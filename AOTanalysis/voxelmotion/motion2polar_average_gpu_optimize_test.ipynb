{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "137b0fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tank/zhangs/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/tank/zhangs/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.4' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "from himalaya.ridge import RidgeCV\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from AOTaccess.stimulus_info_access import StimuliInfoAccess\n",
    "from AOTaccess.glmsingle_access import GLMSingleAccess\n",
    "\n",
    "from himalaya.backend import set_backend\n",
    "\n",
    "# Set backend with a fallback for numpy operations\n",
    "backend = set_backend(\"torch_cuda\", on_error=\"warn\")\n",
    "\n",
    "from AOTanalysis.bandedRR.utils import (\n",
    "    reshape_from_flatten_masked_to_wholebrain,\n",
    ")\n",
    "from AOTanalysis.voxelsemantic.corpus_construct import construct_AOT_corpus\n",
    "import joblib\n",
    "from pprint import pprint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nibabel import Nifti1Image\n",
    "\n",
    "import cortex\n",
    "import torch\n",
    "\n",
    "from AOTanalysis.voxelmotion.filter_info import FilterInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a9e83eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = 3\n",
    "model_path = f\"/tank/shared/2024/visual/AOT/temp/bandedRR_split_single_feature_withSTD_session_testinside_old_Ycentered/model_sub{sub}_feature_motion32_trainses_1_Xcentered_True_Ycentered_True_Xstd_True_testinside.joblib\"\n",
    "model = joblib.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f038b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(n_features, n_voxels) = (11845, 352914)\n"
     ]
    }
   ],
   "source": [
    "primal_coef = model[-1].get_primal_coef()\n",
    "# Keep as a GPU tensor if possible\n",
    "if hasattr(primal_coef, 'is_cuda') and primal_coef.is_cuda:\n",
    "    # Already on GPU, great!\n",
    "    pass\n",
    "else:\n",
    "    # Need to convert to numpy then to a GPU tensor\n",
    "    primal_coef = backend.to_numpy(primal_coef)\n",
    "\n",
    "print(\"(n_features, n_voxels) =\", primal_coef.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5420ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_number, voxel_number) = 11845 352914\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 15.57 GiB. GPU 0 has a total capacity of 14.57 GiB of which 14.21 GiB is free. Process 3778981 has 120.00 MiB memory in use. Process 3799465 has 120.00 MiB memory in use. Including non-PyTorch memory, this process has 120.00 MiB memory in use. Of the allocated memory 1.35 MiB is allocated by PyTorch, and 18.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature_number, voxel_number) =\u001b[39m\u001b[38;5;124m\"\u001b[39m, feature_number, voxel_number)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Convert primal_coef to PyTorch tensor and move to GPU\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m primal_coef_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprimal_coef\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Pre-compute polar angles for all features and convert to tensor\u001b[39;00m\n\u001b[1;32m     10\u001b[0m polar_angles \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([filter_info\u001b[38;5;241m.\u001b[39mindex_to_polar_angle(j) \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(feature_number)])\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 15.57 GiB. GPU 0 has a total capacity of 14.57 GiB of which 14.21 GiB is free. Process 3778981 has 120.00 MiB memory in use. Process 3799465 has 120.00 MiB memory in use. Including non-PyTorch memory, this process has 120.00 MiB memory in use. Of the allocated memory 1.35 MiB is allocated by PyTorch, and 18.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "feature_number = primal_coef.shape[0]\n",
    "voxel_number = primal_coef.shape[1]\n",
    "filter_info = FilterInfo()\n",
    "print(\"feature_number, voxel_number) =\", feature_number, voxel_number)\n",
    "\n",
    "# Convert primal_coef to PyTorch tensor and move to GPU\n",
    "primal_coef_tensor = torch.tensor(primal_coef, device='cuda')\n",
    "\n",
    "# Pre-compute polar angles for all features and convert to tensor\n",
    "polar_angles = np.array([filter_info.index_to_polar_angle(j) for j in range(feature_number)])\n",
    "polar_angles_tensor = torch.tensor(polar_angles, device='cuda')\n",
    "\n",
    "# Calculate absolute sum of coefficients for each voxel\n",
    "abs_sums = torch.sum(torch.abs(primal_coef_tensor), dim=0)\n",
    "\n",
    "# Handle zero sums to avoid division by zero\n",
    "valid_sums_mask = abs_sums > 0\n",
    "\n",
    "# Create normalized coefficients (vectorized operation)\n",
    "normalized_coefs = torch.zeros_like(primal_coef_tensor)\n",
    "normalized_coefs[:, valid_sums_mask] = primal_coef_tensor[:, valid_sums_mask] / abs_sums[valid_sums_mask]\n",
    "\n",
    "# Calculate weighted sum of polar angles (vectorized matrix multiplication)\n",
    "# Shape: [n_features, n_voxels] * [n_features, 1] = [n_voxels]\n",
    "average_polar_angles = torch.matmul(normalized_coefs.T, polar_angles_tensor.unsqueeze(1)).squeeze(1)\n",
    "\n",
    "# Convert back to numpy for further processing\n",
    "average_polar_angles = average_polar_angles.cpu().numpy()\n",
    "\n",
    "# Reshape to whole brain volume\n",
    "average_polar_angles_volume = reshape_from_flatten_masked_to_wholebrain(average_polar_angles, sub)\n",
    "print(\"average_polar_angles_volume.shape =\", average_polar_angles_volume.shape)\n",
    "\n",
    "# Transpose the volume to match the expected shape (106, 95, 84)\n",
    "average_polar_angles_volume = np.transpose(average_polar_angles_volume, (2, 1, 0))\n",
    "print(\"Transposed polar angles volume shape:\", average_polar_angles_volume.shape)\n",
    "\n",
    "glminfo = GLMSingleAccess()\n",
    "affine = glminfo.read_affine(sub)\n",
    "header = glminfo.read_header(sub)\n",
    "\n",
    "save_path = Path(f\"/tank/shared/2024/visual/AOT/temp/motion_energy_analysis/motion2polar_average\")\n",
    "save_path.mkdir(parents=True, exist_ok=True)\n",
    "nifti_img = Nifti1Image(average_polar_angles_volume, affine=affine, header=header)\n",
    "nifti_img.to_filename(save_path / f\"average_polar_angles_sub{sub}_optimize_test.nii.gz\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef36425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: The polar_angles_volume has been transposed to match the expected shape for cortex.Volume\n",
    "sub = \"sub-003\"\n",
    "volume = cortex.Volume(average_polar_angles_volume, sub, \"AOT1pt7mm\", recache=True)\n",
    "mapper = cortex.get_mapper(sub, \"AOT1pt7mm\", type=\"nearest\", recache=True)\n",
    "native_surface_map = mapper(volume)\n",
    "\n",
    "# Set colormap\n",
    "selected_cmap = \"hsv\"  # Change this to your desired colormap\n",
    "native_surface_map.cmap = selected_cmap\n",
    "\n",
    "cortex.quickshow(\n",
    "    native_surface_map,\n",
    "    with_curvature=True,\n",
    "    with_colorbar=True,\n",
    "    with_labels=False,\n",
    "    with_sulci=True,\n",
    "    with_legend=False,\n",
    "    cmap=selected_cmap,\n",
    "    colorbar_label=\"Polar Angle\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3380d5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmarking cell to compare original vs optimized approach\n",
    "import time\n",
    "from functools import wraps\n",
    "\n",
    "def timing_decorator(func):\n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        print(f\"Function {func.__name__} took {end_time - start_time:.4f} seconds to execute\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "@timing_decorator\n",
    "def original_implementation(primal_coef, filter_info):\n",
    "    feature_number = primal_coef.shape[0]\n",
    "    voxel_number = primal_coef.shape[1]\n",
    "    average_polar_angles = np.zeros((voxel_number))\n",
    "    \n",
    "    for i in range(voxel_number):\n",
    "        voxel_coefs = primal_coef[:, i]\n",
    "        abs_sum = torch.sum(torch.abs(torch.tensor(voxel_coefs))).item()\n",
    "        voxel_coefs_normalized = voxel_coefs / abs_sum if abs_sum > 0 else np.zeros_like(voxel_coefs)\n",
    "        \n",
    "        average_polar_angle = 0\n",
    "        for j in range(feature_number):\n",
    "            polar_angle = filter_info.index_to_polar_angle(j)\n",
    "            average_polar_angle += voxel_coefs_normalized[j] * polar_angle\n",
    "        \n",
    "        average_polar_angles[i] = average_polar_angle\n",
    "    \n",
    "    return average_polar_angles\n",
    "\n",
    "@timing_decorator\n",
    "def optimized_implementation(primal_coef, filter_info):\n",
    "    feature_number = primal_coef.shape[0]\n",
    "    voxel_number = primal_coef.shape[1]\n",
    "    \n",
    "    # Convert to PyTorch tensor and move to GPU\n",
    "    if not isinstance(primal_coef, torch.Tensor):\n",
    "        primal_coef_tensor = torch.tensor(primal_coef, device='cuda')\n",
    "    else:\n",
    "        primal_coef_tensor = primal_coef.to('cuda')\n",
    "    \n",
    "    # Pre-compute polar angles for all features\n",
    "    polar_angles = np.array([filter_info.index_to_polar_angle(j) for j in range(feature_number)])\n",
    "    polar_angles_tensor = torch.tensor(polar_angles, device='cuda').unsqueeze(1)\n",
    "    \n",
    "    # Calculate absolute sum of coefficients\n",
    "    abs_sums = torch.sum(torch.abs(primal_coef_tensor), dim=0)\n",
    "    \n",
    "    # Create normalized coefficients with zero handling\n",
    "    normalized_coefs = torch.zeros_like(primal_coef_tensor)\n",
    "    valid_mask = abs_sums > 0\n",
    "    normalized_coefs[:, valid_mask] = primal_coef_tensor[:, valid_mask] / abs_sums[valid_mask]\n",
    "    \n",
    "    # Calculate weighted sum of polar angles (vectorized)\n",
    "    average_polar_angles = torch.matmul(normalized_coefs.T, polar_angles_tensor).squeeze(1)\n",
    "    \n",
    "    return average_polar_angles.cpu().numpy()\n",
    "\n",
    "# Run both implementations with a small subset to verify correctness\n",
    "small_coef = primal_coef[:, :1000] if isinstance(primal_coef, np.ndarray) else backend.to_numpy(primal_coef)[:, :1000]\n",
    "\n",
    "print(\"Testing with a subset of\", small_coef.shape[1], \"voxels\")\n",
    "#original_result = original_implementation(small_coef, filter_info)\n",
    "optimized_result = optimized_implementation(small_coef, filter_info)\n",
    "\n",
    "# # Check if results match\n",
    "# print(\"Results match:\", np.allclose(original_result, optimized_result, rtol=1e-5, atol=1e-5))\n",
    "# print(\"Mean absolute difference:\", np.mean(np.abs(original_result - optimized_result)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
